{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gw2xyVF9y29a"
      },
      "source": [
        "# Lab 3: Quantitized Model Benchmarking Efficiency in Feed-Forward Neural Networks.\n",
        "\n",
        "**Team Cyclops**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BOslHvZy29d",
        "outputId": "081742f5-2531-40ba-db05-b15e013be158"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device:  cpu\n"
          ]
        }
      ],
      "source": [
        "# Below is the code for building the network\n",
        "\n",
        "import torch\n",
        "import csv\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import torchvision\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(\"Device: \", device)\n",
        "\n",
        "trainPath = \"./MNIST/mnist_train.csv\"\n",
        "testPath = \"./MNIST/mnist_test.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 653
        },
        "id": "Zq-YpgLty29e",
        "outputId": "c95d4639-8d24-4217-eaa4-4d8928898ce9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Define Dataloader\n",
        "class MNISTDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, fileName: str, transform = None):\n",
        "        self.X_Data, self.Y_Data = [], []\n",
        "\n",
        "        with open(fileName, mode = 'r') as f:\n",
        "\n",
        "            csvreader = csv.reader(f)\n",
        "\n",
        "            for line in csvreader:\n",
        "                row = list(map(int, line))\n",
        "\n",
        "                pixels = row[1:]\n",
        "                label = row[0]\n",
        "\n",
        "                pixels = (pixels - np.mean(pixels, axis = 0))/np.std(pixels, axis = 0)\n",
        "\n",
        "                self.X_Data.append(pixels)\n",
        "                self.Y_Data.append(label)\n",
        "\n",
        "        self.transform = transform\n",
        "        self.length = len(self.Y_Data)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        X_tensor = torch.FloatTensor(self.X_Data[idx])\n",
        "        Y_tensor = torch.tensor(self.Y_Data[idx])\n",
        "\n",
        "        if self.transform:\n",
        "            X_tensor = self.transform(X_tensor)\n",
        "\n",
        "        return X_tensor, Y_tensor\n",
        "\n",
        "\n",
        "\n",
        "trainMNIST  = MNISTDataset(trainPath, None)\n",
        "testMNIST = MNISTDataset(testPath, None)\n",
        "\n",
        "train_loader_temp = torch.utils.data.DataLoader(\n",
        "    dataset = trainMNIST,\n",
        "    batch_size = 64,\n",
        "    shuffle = True\n",
        ")\n",
        "\n",
        "test_loader_temp = torch.utils.data.DataLoader(\n",
        "    dataset = testMNIST,\n",
        "    batch_size = 64,\n",
        "    shuffle = True\n",
        ")\n",
        "\n",
        "\n",
        "r, c = [2, 2]\n",
        "fig, ax = plt.subplots(r, c, figsize= (8, 8))\n",
        "\n",
        "k = 0\n",
        "\n",
        "for data in train_loader_temp:\n",
        "    x, y = data\n",
        "\n",
        "    for i in range(r):\n",
        "        for j in range(c):\n",
        "            img = x[k].numpy().reshape(28, 28)\n",
        "            ax[i, j].imshow(img)\n",
        "            ax[i, j].axis('off')\n",
        "            k += 1\n",
        "\n",
        "    break\n",
        "\n",
        "del train_loader_temp, test_loader_temp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ywZtfGszy29f"
      },
      "outputs": [],
      "source": [
        "def trainLoop(inputModel, inputOptimizer, inputCriterion, dataloader, num_epochs = 2):\n",
        "\n",
        "    startTime = time.time()\n",
        "\n",
        "    # Looping over the epochs\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        # Putting the model in training loop\n",
        "        inputModel.train()\n",
        "\n",
        "        runningLoss = 0\n",
        "\n",
        "        for pixels, labels in dataloader:\n",
        "\n",
        "            # Zeroing the gradients\n",
        "            inputOptimizer.zero_grad()\n",
        "\n",
        "            # Forward Pass\n",
        "            outputs = inputModel(pixels)\n",
        "            loss = inputCriterion(outputs, labels)\n",
        "\n",
        "            # Backprop\n",
        "            loss.backward()\n",
        "            inputOptimizer.step()\n",
        "\n",
        "            runningLoss += loss.item()\n",
        "\n",
        "        epochLoss = runningLoss/len(dataloader)\n",
        "        # print(f'Epoch [{epoch+1}/{num_epochs}] Loss: {epochLoss:.4f}')\n",
        "    endTime = time.time()\n",
        "    return (endTime - startTime)/num_epochs\n",
        "\n",
        "\n",
        "def testLoop(inputModel, dataloader, batch_size):\n",
        "\n",
        "    startTime = time.time()\n",
        "\n",
        "    correct_predictions = 0\n",
        "    total_predicitions = 0\n",
        "\n",
        "    # Putting the model in evaluation mode\n",
        "    inputModel.eval()\n",
        "\n",
        "    # Ensuring no gradients are calculated\n",
        "    with torch.no_grad():\n",
        "        for pixels, numbers in dataloader:\n",
        "\n",
        "            # Forward Pass\n",
        "            outputs = inputModel(pixels)\n",
        "\n",
        "            # Inference\n",
        "            correct_predictions += torch.sum(torch.argmax(outputs, dim = 1) == numbers).item()\n",
        "            total_predicitions += len(numbers)\n",
        "\n",
        "\n",
        "    accuracy = 100 * correct_predictions/total_predicitions\n",
        "    endTime = time.time()\n",
        "    return accuracy, (endTime - startTime)/(len(dataloader)*batch_size)\n",
        "\n",
        "\n",
        "\n",
        "# Computing the Parameters in the model\n",
        "def getParams(inputModel):\n",
        "\n",
        "    model_size = 0\n",
        "    for f in inputModel.parameters():\n",
        "        if f.requires_grad:\n",
        "\n",
        "            model_size += f.numel()\n",
        "\n",
        "    return model_size\n",
        "\n",
        "# Computing FLOPS\n",
        "def getFLOPS(inputModel):\n",
        "\n",
        "    flops = 0\n",
        "\n",
        "    for f in inputModel.parameters():\n",
        "        if f.requires_grad:\n",
        "\n",
        "            if f.ndim == 1:\n",
        "                flops += 2*f.shape[0]\n",
        "            else:\n",
        "                flops += 2*f.shape[0]*f.shape[1]\n",
        "\n",
        "    return flops\n",
        "\n",
        "def print_size_of_model(model, label=\"\"):\n",
        "    torch.save(model.state_dict(), \"temp.p\")\n",
        "    size=os.path.getsize(\"temp.p\")\n",
        "    print(\"model: \",label,' \\t','Size (MB):', size/1e6)\n",
        "    os.remove('temp.p')\n",
        "    return size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "sBerVaG1y29g"
      },
      "outputs": [],
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "    dataset = trainMNIST,\n",
        "    batch_size = 64,\n",
        "    shuffle = True\n",
        ")\n",
        "\n",
        "test_loader_1 = torch.utils.data.DataLoader(\n",
        "    dataset = testMNIST,\n",
        "    batch_size = 1,\n",
        "    shuffle = True\n",
        ")\n",
        "\n",
        "test_loader_64 = torch.utils.data.DataLoader(\n",
        "    dataset = testMNIST,\n",
        "    batch_size = 64,\n",
        "    shuffle = True\n",
        ")\n",
        "\n",
        "# BaseLine Model\n",
        "class BaselineMLP(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, input_size = 784, output_size = 10, hidden_size = 1024):\n",
        "\n",
        "        super(BaselineMLP, self).__init__()\n",
        "\n",
        "        self.model = torch.nn.Sequential(\n",
        "            torch.nn.Linear(input_size, hidden_size),\n",
        "            torch.nn.ReLU(),\n",
        "\n",
        "            torch.nn.Linear(hidden_size, hidden_size),\n",
        "            torch.nn.ReLU(),\n",
        "\n",
        "            torch.nn.Linear(hidden_size, output_size)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        out = self.model(x)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6pAiykIy29g"
      },
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kn9gxjX1y29g",
        "outputId": "c49761a6-e342-458c-f7b6-cf788a96d980"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training time per epoch:  36.86110031604767\n",
            "Model precision: fp32\n",
            "model:    \t Size (MB): 7.457066\n",
            "Number of parameters: 1863690\n"
          ]
        }
      ],
      "source": [
        "baseline_model  = BaselineMLP(input_size = 784, output_size = 10, hidden_size = 1024).to(device)\n",
        "baseline_criterion = torch.nn.CrossEntropyLoss()\n",
        "baseline_optimizer = torch.optim.Adam(baseline_model.parameters(), lr = 0.001)\n",
        "\n",
        "predTime = trainLoop(inputModel = baseline_model, inputOptimizer = baseline_optimizer, inputCriterion = baseline_criterion, dataloader = train_loader, num_epochs = 2)\n",
        "print(\"Training time per epoch: \", predTime)\n",
        "\n",
        "print(\"Model precision: fp32\")\n",
        "model_size_storgae = print_size_of_model(baseline_model)\n",
        "\n",
        "model_size_params = getParams(baseline_model)\n",
        "print(\"Number of parameters: {}\".format(model_size_params))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYbFgJv8y29h"
      },
      "source": [
        "### Batch Size 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_FasIOhy29h",
        "outputId": "27201954-9387-49f1-aec6-7445290e81e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Run- 1\n",
            "Inference Time:  0.0006511002779006958\n",
            "Testing Accuracy:  97.26\n",
            "\n",
            "Run- 2\n",
            "Inference Time:  0.0008302306890487671\n",
            "Testing Accuracy:  97.26\n",
            "\n",
            "Run- 3\n",
            "Inference Time:  0.0009377162933349609\n",
            "Testing Accuracy:  97.26\n",
            "\n",
            "Run- 4\n",
            "Inference Time:  0.0007250999927520752\n",
            "Testing Accuracy:  97.26\n",
            "\n",
            "Run- 5\n",
            "Inference Time:  0.0008703519821166992\n",
            "Testing Accuracy:  97.26\n",
            "\n",
            "\n",
            "Average Accuracy: 97.26\n",
            "Average Inference Time: 0.0008028998470306397\n",
            "Std Inference Time: 0.00010253600944157743\n"
          ]
        }
      ],
      "source": [
        "# Batch Size 1 experiments\n",
        "all_accuracies_1, all_inference_1 = [], []\n",
        "for i in range(5):\n",
        "    print(\"\\nRun-\", (i + 1))\n",
        "    baselineAcc, baselineInf = testLoop(inputModel = baseline_model, dataloader = test_loader_1, batch_size = 1)\n",
        "\n",
        "    all_accuracies_1.append(baselineAcc)\n",
        "    all_inference_1.append(baselineInf)\n",
        "\n",
        "    print(\"Inference Time: \", baselineInf)\n",
        "    print(\"Testing Accuracy: \", baselineAcc)\n",
        "\n",
        "\n",
        "print(\"\\n\\nAverage Accuracy: {}\".format(np.array(all_accuracies_1).mean()))\n",
        "print(\"Average Inference Time: {}\".format(np.array(all_inference_1).mean()))\n",
        "print(\"Std Inference Time: {}\".format(np.array(all_inference_1).std ()))\n",
        "\n",
        "del all_accuracies_1, all_inference_1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgP9I8ksy29h"
      },
      "source": [
        "### Batch Size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jRMNYMuy29h",
        "outputId": "817f9bd9-8b1b-4b70-de85-359e8a7812f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Run- 1\n",
            "Inference Time:  0.00010992743217261733\n",
            "Testing Accuracy:  97.26\n",
            "\n",
            "Run- 2\n",
            "Inference Time:  0.00010708097819310085\n",
            "Testing Accuracy:  97.26\n",
            "\n",
            "Run- 3\n",
            "Inference Time:  0.00010973682544033998\n",
            "Testing Accuracy:  97.26\n",
            "\n",
            "Run- 4\n",
            "Inference Time:  0.00010689511705356039\n",
            "Testing Accuracy:  97.26\n",
            "\n",
            "Run- 5\n",
            "Inference Time:  0.00010886543970199147\n",
            "Testing Accuracy:  97.26\n",
            "\n",
            "\n",
            "Average Accuracy: 97.26\n",
            "Average Inference Time: 0.000108501158512322\n",
            "Std Inference Time: 1.2876421399255966e-06\n"
          ]
        }
      ],
      "source": [
        "# Batch Size 64 experiments\n",
        "all_accuracies_64, all_inference_64 = [], []\n",
        "for i in range(5):\n",
        "    print(\"\\nRun-\", (i + 1))\n",
        "    baselineAcc, baselineInf = testLoop(inputModel = baseline_model, dataloader = test_loader_64, batch_size = 64)\n",
        "\n",
        "    all_accuracies_64.append(baselineAcc)\n",
        "    all_inference_64.append(baselineInf)\n",
        "\n",
        "    print(\"Inference Time: \", baselineInf)\n",
        "    print(\"Testing Accuracy: \", baselineAcc)\n",
        "\n",
        "print(\"\\n\\nAverage Accuracy: {}\".format(np.array(all_accuracies_64).mean()))\n",
        "print(\"Average Inference Time: {}\".format(np.array(all_inference_64).mean()))\n",
        "print(\"Std Inference Time: {}\".format(np.array(all_inference_64).std ()))\n",
        "\n",
        "del all_accuracies_64, all_inference_64"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnFFZew6y29h"
      },
      "source": [
        "# Dynamic quantization in PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "_CzmZa2vy29h"
      },
      "outputs": [],
      "source": [
        "from torch.quantization.quantize_fx import prepare_fx, prepare_qat_fx, convert_fx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1HJNykby29h"
      },
      "source": [
        "## Float 16 Quantization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opB2qvp_y29h",
        "outputId": "a4bed5dc-5a2a-4f24-9fb4-755fe72f269e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model precision: float16\n",
            "model:    \t Size (MB): 7.458946\n"
          ]
        }
      ],
      "source": [
        "torch.backends.quantized.engine = 'fbgemm'\n",
        "model_dynamic_float_16 = torch.quantization.quantize_dynamic(baseline_model, {torch.nn.Linear}, dtype=torch.float16)\n",
        "\n",
        "print(\"Model precision: float16\")\n",
        "model_size_storgae = print_size_of_model(model_dynamic_float_16)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_olkKgAy29h"
      },
      "source": [
        "### Batch Size 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1TG7sILy29h",
        "outputId": "f25aea1f-754b-4ef9-c465-444d0e397678"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Run- 1\n",
            "Inference Time:  0.0007602653503417969\n",
            "Testing Accuracy:  97.26\n",
            "\n",
            "Run- 2\n",
            "Inference Time:  0.0007257496356964111\n",
            "Testing Accuracy:  97.26\n",
            "\n",
            "Run- 3\n",
            "Inference Time:  0.0007013635396957398\n",
            "Testing Accuracy:  97.26\n",
            "\n",
            "Run- 4\n",
            "Inference Time:  0.0007522077798843384\n",
            "Testing Accuracy:  97.26\n",
            "\n",
            "Run- 5\n",
            "Inference Time:  0.0007139513254165649\n",
            "Testing Accuracy:  97.26\n",
            "\n",
            "\n",
            "Average Accuracy: 97.26\n",
            "Average Inference Time: 0.0007307075262069703\n",
            "Std Inference Time: 2.237117057013723e-05\n"
          ]
        }
      ],
      "source": [
        "# Batch Size 1 experiments\n",
        "all_accuracies_float16_1, all_inference_float16_1 = [], []\n",
        "for i in range(5):\n",
        "    print(\"\\nRun-\", (i + 1))\n",
        "    baselineAcc, baselineInf = testLoop(inputModel = model_dynamic_float_16, dataloader = test_loader_1, batch_size = 1)\n",
        "\n",
        "    all_accuracies_float16_1.append(baselineAcc)\n",
        "    all_inference_float16_1.append(baselineInf)\n",
        "\n",
        "    print(\"Inference Time: \", baselineInf)\n",
        "    print(\"Testing Accuracy: \", baselineAcc)\n",
        "\n",
        "\n",
        "print(\"\\n\\nAverage Accuracy: {}\".format(np.array(all_accuracies_float16_1).mean()))\n",
        "print(\"Average Inference Time: {}\".format(np.array(all_inference_float16_1).mean()))\n",
        "print(\"Std Inference Time: {}\".format(np.array(all_inference_float16_1).std ()))\n",
        "\n",
        "del all_accuracies_float16_1, all_inference_float16_1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CmTZ8Bky29i"
      },
      "source": [
        "### Batch Size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLVlBZp8y29i",
        "outputId": "6af7ff10-12f1-4b9d-dc68-766d63fcd4c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Run- 1\n",
            "Inference Time:  0.00010344044418091987\n",
            "Testing Accuracy:  97.26\n",
            "\n",
            "Run- 2\n",
            "Inference Time:  0.00011499233211681342\n",
            "Testing Accuracy:  97.26\n",
            "\n",
            "Run- 3\n",
            "Inference Time:  0.00016427047218486762\n",
            "Testing Accuracy:  97.26\n",
            "\n",
            "Run- 4\n",
            "Inference Time:  0.00013517341606176584\n",
            "Testing Accuracy:  97.26\n",
            "\n",
            "Run- 5\n",
            "Inference Time:  0.00010245544895245012\n",
            "Testing Accuracy:  97.26\n",
            "\n",
            "\n",
            "Average Accuracy: 97.26\n",
            "Average Inference Time: 0.00012406642269936335\n",
            "Std Inference Time: 2.3300365630687924e-05\n"
          ]
        }
      ],
      "source": [
        "# Batch Size 64 experiments\n",
        "all_accuracies_float16_64, all_inference_float16_64 = [], []\n",
        "for i in range(5):\n",
        "    print(\"\\nRun-\", (i + 1))\n",
        "    baselineAcc, baselineInf = testLoop(inputModel = model_dynamic_float_16, dataloader = test_loader_64, batch_size = 64)\n",
        "\n",
        "    all_accuracies_float16_64.append(baselineAcc)\n",
        "    all_inference_float16_64.append(baselineInf)\n",
        "\n",
        "    print(\"Inference Time: \", baselineInf)\n",
        "    print(\"Testing Accuracy: \", baselineAcc)\n",
        "\n",
        "print(\"\\n\\nAverage Accuracy: {}\".format(np.array(all_accuracies_float16_64).mean()))\n",
        "print(\"Average Inference Time: {}\".format(np.array(all_inference_float16_64).mean()))\n",
        "print(\"Std Inference Time: {}\".format(np.array(all_inference_float16_64).std ()))\n",
        "\n",
        "del all_accuracies_float16_64, all_inference_float16_64"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQyDEuH_y29i"
      },
      "source": [
        "# q INT8 Quantization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHqu_LVEy29i",
        "outputId": "583ebc88-1dea-4797-bca2-40b112aecbc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model precision: qint8\n",
            "model:    \t Size (MB): 1.87405\n"
          ]
        }
      ],
      "source": [
        "torch.backends.quantized.engine = 'qnnpack'\n",
        "model_dynamic_q_int8 = torch.quantization.quantize_dynamic(baseline_model, {torch.nn.Linear}, dtype=torch.qint8)\n",
        "\n",
        "print(\"Model precision: qint8\")\n",
        "model_size_storgae = print_size_of_model(model_dynamic_q_int8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5Re1kqHy29i"
      },
      "source": [
        "### Batch Size 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxCJTgwgy29i",
        "outputId": "cd862beb-ac38-40fc-e3aa-c595a0f80b85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Run- 1\n",
            "Inference Time:  0.0016380500316619873\n",
            "Testing Accuracy:  97.25\n",
            "\n",
            "Run- 2\n",
            "Inference Time:  0.002002140474319458\n",
            "Testing Accuracy:  97.25\n",
            "\n",
            "Run- 3\n",
            "Inference Time:  0.0016841702461242675\n",
            "Testing Accuracy:  97.25\n",
            "\n",
            "Run- 4\n",
            "Inference Time:  0.0017914504528045655\n",
            "Testing Accuracy:  97.25\n",
            "\n",
            "Run- 5\n",
            "Inference Time:  0.0016788361310958863\n",
            "Testing Accuracy:  97.25\n",
            "\n",
            "\n",
            "Average Accuracy: 97.25\n",
            "Average Inference Time: 0.001758929467201233\n",
            "Std Inference Time: 0.00013177627255987995\n"
          ]
        }
      ],
      "source": [
        "# Batch Size 1 experiments\n",
        "all_accuracies_qint8_1, all_inference_qint8_1 = [], []\n",
        "for i in range(5):\n",
        "    print(\"\\nRun-\", (i + 1))\n",
        "    baselineAcc, baselineInf = testLoop(inputModel = model_dynamic_q_int8, dataloader = test_loader_1, batch_size = 1)\n",
        "\n",
        "    all_accuracies_qint8_1.append(baselineAcc)\n",
        "    all_inference_qint8_1.append(baselineInf)\n",
        "\n",
        "    print(\"Inference Time: \", baselineInf)\n",
        "    print(\"Testing Accuracy: \", baselineAcc)\n",
        "\n",
        "\n",
        "print(\"\\n\\nAverage Accuracy: {}\".format(np.array(all_accuracies_qint8_1).mean()))\n",
        "print(\"Average Inference Time: {}\".format(np.array(all_inference_qint8_1).mean()))\n",
        "print(\"Std Inference Time: {}\".format(np.array(all_inference_qint8_1).std ()))\n",
        "\n",
        "del all_accuracies_qint8_1, all_inference_qint8_1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2bKHBP_y29i"
      },
      "source": [
        "### Batch Size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4OEtvpp1y29i",
        "outputId": "2fc93a8f-f468-415b-a91a-7dd33cc5d36c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Run- 1\n",
            "Inference Time:  0.00023995959170305045\n",
            "Testing Accuracy:  97.25\n",
            "\n",
            "Run- 2\n",
            "Inference Time:  0.0002377419999450635\n",
            "Testing Accuracy:  97.28\n",
            "\n",
            "Run- 3\n",
            "Inference Time:  0.00037084398850513873\n",
            "Testing Accuracy:  97.26\n",
            "\n",
            "Run- 4\n",
            "Inference Time:  0.0002378223428300991\n",
            "Testing Accuracy:  97.28\n",
            "\n",
            "Run- 5\n",
            "Inference Time:  0.00023568625662736832\n",
            "Testing Accuracy:  97.26\n",
            "\n",
            "\n",
            "Average Accuracy: 97.266\n",
            "Average Inference Time: 0.00026441083592214403\n",
            "Std Inference Time: 5.3233740326144264e-05\n"
          ]
        }
      ],
      "source": [
        "# Batch Size 64 experiments\n",
        "all_accuracies_qint8_64, all_inference_qint8_64 = [], []\n",
        "for i in range(5):\n",
        "    print(\"\\nRun-\", (i + 1))\n",
        "    baselineAcc, baselineInf = testLoop(inputModel = model_dynamic_q_int8, dataloader = test_loader_64, batch_size = 64)\n",
        "\n",
        "    all_accuracies_qint8_64.append(baselineAcc)\n",
        "    all_inference_qint8_64.append(baselineInf)\n",
        "\n",
        "    print(\"Inference Time: \", baselineInf)\n",
        "    print(\"Testing Accuracy: \", baselineAcc)\n",
        "\n",
        "print(\"\\n\\nAverage Accuracy: {}\".format(np.array(all_accuracies_qint8_64).mean()))\n",
        "print(\"Average Inference Time: {}\".format(np.array(all_inference_qint8_64).mean()))\n",
        "print(\"Std Inference Time: {}\".format(np.array(all_inference_qint8_64).std ()))\n",
        "\n",
        "del all_accuracies_qint8_64, all_inference_qint8_64"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXL9Avsyy29i"
      },
      "source": [
        "# Static Quantization (q INT8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhXnfqI_y29i",
        "outputId": "1d9cf4a2-075d-4bb1-805b-417f50849b45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model precision: qint8\n",
            "model:    \t Size (MB): 1.87405\n"
          ]
        }
      ],
      "source": [
        "from torch.quantization.quantize_fx import prepare_fx, prepare_qat_fx, convert_fx\n",
        "qconfig_mapping = torch.ao.quantization.get_default_qconfig_mapping(\"qnnpack\")\n",
        "quantized_model = torch.ao.quantization.quantize_fx.prepare_fx(baseline_model, qconfig_mapping, torch.randn(784, 1000))\n",
        "\n",
        "def calibrate(model, dataloader):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for input in dataloader:\n",
        "            model(input[0])\n",
        "\n",
        "calibrate(quantized_model, train_loader)\n",
        "static_quantized_model_int8 = torch.ao.quantization.quantize_fx.convert_fx(quantized_model)\n",
        "\n",
        "print(\"Model precision: qint8\")\n",
        "model_size_storgae = print_size_of_model(model_dynamic_q_int8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jE2AUY-ly29i"
      },
      "source": [
        "### Batch Size 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZ4Wt5wAy29i",
        "outputId": "62f82eab-69d4-41f1-f484-f46b496608b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Run- 1\n",
            "Inference Time:  0.0014089105367660522\n",
            "Testing Accuracy:  97.31\n",
            "\n",
            "Run- 2\n",
            "Inference Time:  0.0013936184644699097\n",
            "Testing Accuracy:  97.31\n",
            "\n",
            "Run- 3\n",
            "Inference Time:  0.0016366063117980957\n",
            "Testing Accuracy:  97.31\n",
            "\n",
            "Run- 4\n",
            "Inference Time:  0.001569526243209839\n",
            "Testing Accuracy:  97.31\n",
            "\n",
            "Run- 5\n",
            "Inference Time:  0.0013838932514190674\n",
            "Testing Accuracy:  97.31\n",
            "\n",
            "\n",
            "Average Accuracy: 97.31\n",
            "Average Inference Time: 0.0014785109615325929\n",
            "Std Inference Time: 0.00010419346191264418\n"
          ]
        }
      ],
      "source": [
        "# Batch Size 1 experiments\n",
        "all_accuracies_qint8_1, all_inference_qint8_1 = [], []\n",
        "for i in range(5):\n",
        "    print(\"\\nRun-\", (i + 1))\n",
        "    baselineAcc, baselineInf = testLoop(inputModel = static_quantized_model_int8, dataloader = test_loader_1, batch_size = 1)\n",
        "\n",
        "    all_accuracies_qint8_1.append(baselineAcc)\n",
        "    all_inference_qint8_1.append(baselineInf)\n",
        "\n",
        "    print(\"Inference Time: \", baselineInf)\n",
        "    print(\"Testing Accuracy: \", baselineAcc)\n",
        "\n",
        "print(\"\\n\\nAverage Accuracy: {}\".format(np.array(all_accuracies_qint8_1).mean()))\n",
        "print(\"Average Inference Time: {}\".format(np.array(all_inference_qint8_1).mean()))\n",
        "print(\"Std Inference Time: {}\".format(np.array(all_inference_qint8_1).std ()))\n",
        "\n",
        "del all_accuracies_qint8_1, all_inference_qint8_1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsCQgtAhy29j"
      },
      "source": [
        "### Batch Size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XgsMDy_0y29j",
        "outputId": "1d8b39dd-999e-42e1-f1e2-492b7218b0f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Run- 1\n",
            "Inference Time:  0.0002102187721972253\n",
            "Testing Accuracy:  97.31\n",
            "\n",
            "Run- 2\n",
            "Inference Time:  0.00034498812476540825\n",
            "Testing Accuracy:  97.31\n",
            "\n",
            "Run- 3\n",
            "Inference Time:  0.00020422470892310902\n",
            "Testing Accuracy:  97.31\n",
            "\n",
            "Run- 4\n",
            "Inference Time:  0.0002038094458306671\n",
            "Testing Accuracy:  97.31\n",
            "\n",
            "Run- 5\n",
            "Inference Time:  0.00020741837419522037\n",
            "Testing Accuracy:  97.31\n",
            "\n",
            "\n",
            "Average Accuracy: 97.31\n",
            "Average Inference Time: 0.000234131885182326\n",
            "Std Inference Time: 5.547692135732306e-05\n"
          ]
        }
      ],
      "source": [
        "# Batch Size 64 experiments\n",
        "all_accuracies_qint8_64, all_inference_qint8_64 = [], []\n",
        "for i in range(5):\n",
        "    print(\"\\nRun-\", (i + 1))\n",
        "    baselineAcc, baselineInf = testLoop(inputModel = static_quantized_model_int8, dataloader = test_loader_64, batch_size = 64)\n",
        "\n",
        "    all_accuracies_qint8_64.append(baselineAcc)\n",
        "    all_inference_qint8_64.append(baselineInf)\n",
        "\n",
        "    print(\"Inference Time: \", baselineInf)\n",
        "    print(\"Testing Accuracy: \", baselineAcc)\n",
        "\n",
        "print(\"\\n\\nAverage Accuracy: {}\".format(np.array(all_accuracies_qint8_64).mean()))\n",
        "print(\"Average Inference Time: {}\".format(np.array(all_inference_qint8_64).mean()))\n",
        "print(\"Std Inference Time: {}\".format(np.array(all_inference_qint8_64).std ()))\n",
        "\n",
        "del all_accuracies_qint8_64, all_inference_qint8_64"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2J3a7p7D0A1I"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}